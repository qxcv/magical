{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "demo-notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLCCM5Ev7iDF"
      },
      "source": [
        "# Demo of the MAGICAL benchmark suite for robust IL\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qxcv/magical/blob/pyglet1.5/demo-notebook.ipynb)\n",
        "\n",
        "This self-contained Colab notebook shows how to train a simple imitation learning agent on MAGICAL using behavioural cloning (BC)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vhtm7mY7iDG"
      },
      "source": [
        "# Install MAGICAL, Xvfb, and a prerelease version of the 'imitation' library (https://github.com/HumanCompatibleAI/imitation)\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt-get install -yq xvfb\n",
        "!pip install -qU pip\n",
        "# This usually gives errors of the form \"package W requires version X of package Y, but you'll have version Z which is incompatible\"\n",
        "# You can safely ignore those errors; they are dependency conflicts in the underlying libraries.\n",
        "!pip install --use-feature=2020-resolver -q xvfbwrapper magical-il 'git+git://github.com/HumanCompatibleAI/imitation@556f5d8384d99fa5ab8bc54a9828887a2db8c669#egg=imitation'\n",
        "if 'vdisplay' not in globals():\n",
        "    # start a virtual X display for MAGICAL rendering\n",
        "    import xvfbwrapper\n",
        "    vdisplay = xvfbwrapper.Xvfb()\n",
        "    vdisplay.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie_RQjct7iDH"
      },
      "source": [
        "import glob\n",
        "import logging\n",
        "\n",
        "import gym\n",
        "from imitation.algorithms.bc import BC\n",
        "import imitation.augment as il_augment\n",
        "import imitation.data.types as il_types\n",
        "import numpy as np\n",
        "import stable_baselines3.common.policies as sb3_pols\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as th_data\n",
        "\n",
        "import magical\n",
        "\n",
        "magical.register_envs()\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "# download trajectories\n",
        "magical.try_download_demos(dest=\"demos\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hfHaZG67iDH"
      },
      "source": [
        "env_ident = 'MoveToCorner'\n",
        "preproc_name = 'LoRes4E'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-knOWB17iDH"
      },
      "source": [
        "demo_paths_by_env = {\n",
        "    'MoveToCorner': glob.glob('demos/move-to-corner/demo-*.pkl.gz'),\n",
        "}\n",
        "demo_paths = demo_paths_by_env[env_ident]\n",
        "# Gym env name with preprocessor\n",
        "env_name = f'{env_ident}-Demo-{preproc_name}-v0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHSVWkb87iDI"
      },
      "source": [
        "env = gym.make(env_name)\n",
        "demo_dicts = magical.load_demos(demo_paths[:10])\n",
        "demo_trajs = []\n",
        "orig_env_name = None  # we will read this from the demos dicts\n",
        "for demo_dict in demo_dicts:\n",
        "    # each demo dict has keys ['trajectory', 'score', 'env_name']\n",
        "    # (trajectory contains the actual data, and score is generally 1.0 for demonstrations)\n",
        "    orig_env_name = demo_dict['env_name']\n",
        "    demo_trajs.append(demo_dict['trajectory'])\n",
        "demo_trajs_preproc = magical.preprocess_demos_with_wrapper(demo_trajs, orig_env_name, preproc_name=preproc_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcEkoJI9_gh-"
      },
      "source": [
        "class MAGICALNet(nn.Module):\n",
        "    \"\"\"Custom CNN for MAGICAL policies.\"\"\"\n",
        "    def __init__(self, observation_space, out_chans=256, width=2):\n",
        "        super().__init__()\n",
        "        w = width\n",
        "        def conv_block(i, o, k, s, p, b=False):\n",
        "            return [\n",
        "                # batch norm has its own bias, so don't add one to conv layers by default\n",
        "                nn.Conv2d(i, o, kernel_size=k, stride=s, padding=p, bias=b,\n",
        "                          padding_mode='zeros'),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(o)\n",
        "            ]\n",
        "        conv_layers = [\n",
        "            *conv_block(i=observation_space.shape[0], o=32*w, k=5, s=1, p=2, b=True),\n",
        "            *conv_block(i=32*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "        ]\n",
        "        # final FC layer to make feature maps the right size\n",
        "        test_tensor = torch.zeros((1,) + observation_space.shape)\n",
        "        for layer in conv_layers:\n",
        "            test_tensor = layer(test_tensor)\n",
        "        fc_in_size = np.prod(test_tensor.shape)\n",
        "        reduction_layers = [\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(fc_in_size, out_chans),\n",
        "            # Stable Baselines will add extra affine layer on top of this reLU\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        self.features_dim = out_chans\n",
        "        all_layers = [*conv_layers, *reduction_layers]\n",
        "        self.feature_generator = nn.Sequential(*all_layers)\n",
        "\n",
        "    def forward(self, x, traj_info=None):\n",
        "        return self.feature_generator(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiEV5Nr3jx7x"
      },
      "source": [
        "# Build dataset in the format required by imitation. Note that traj.obs contains the final observation after the last\n",
        "# action, so we drop the last observation when concatenating trajectories.\n",
        "all_obs = np.concatenate([traj.obs[:-1] for traj in demo_trajs_preproc], axis=0)\n",
        "all_acts = np.concatenate([traj.acts for traj in demo_trajs_preproc], axis=0)\n",
        "dataset = il_types.TransitionsMinimal(obs=all_obs, acts=all_acts, infos=[{}] * len(all_obs))\n",
        "data_loader = th_data.DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=il_types.transitions_collate_fn)\n",
        "augmenter = il_augment.StandardAugmentations.from_string_spec(\n",
        "       'rotate,translate,noise', stack_color_space=il_augment.ColorSpace.RGB)\n",
        "bc_trainer = BC(\n",
        "    observation_space=env.observation_space,\n",
        "    action_space=env.action_space,\n",
        "    policy_class=sb3_pols.ActorCriticCnnPolicy,\n",
        "    policy_kwargs=dict(features_extractor_class=MAGICALNet),\n",
        "    expert_data=data_loader,\n",
        "    augmentation_fn=augmenter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2i3K1Fv_DSN"
      },
      "source": [
        "# try training for longer (e.g. 15,000 batches) to get better performance\n",
        "bc_trainer.train(n_batches=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umG_LZNGCO9y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}