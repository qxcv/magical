{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "demo-notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLCCM5Ev7iDF"
      },
      "source": [
        "# Demo of the MAGICAL benchmark suite for robust IL\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qxcv/magical/blob/pyglet1.5/demo-notebook.ipynb)\n",
        "\n",
        "This self-contained Colab notebook shows how to train a simple imitation learning agent on MAGICAL using behavioural cloning (BC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1my5TdGlh-O"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vhtm7mY7iDG"
      },
      "source": [
        "# Install MAGICAL, Xvfb, and a prerelease version of the 'imitation' library (https://github.com/HumanCompatibleAI/imitation)\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt-get install -yq xvfb\n",
        "!pip install -qU pip\n",
        "# This usually gives errors of the form \"package W requires version X of package Y, but you'll have version Z which is\n",
        "# incompatible\". You can safely ignore those errors; I suspect they are conflicts in the Colab environment.\n",
        "!pip install --use-feature=2020-resolver -q magical-il scikit-video~=1.1.11 xvfbwrapper~=0.2.9 'git+git://github.com/HumanCompatibleAI/imitation@556f5d8384d99fa5ab8bc54a9828887a2db8c669#egg=imitation'\n",
        "if 'vdisplay' not in globals():\n",
        "    # start a virtual X display for MAGICAL rendering\n",
        "    import xvfbwrapper\n",
        "    vdisplay = xvfbwrapper.Xvfb()\n",
        "    vdisplay.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie_RQjct7iDH"
      },
      "source": [
        "import base64\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import gym\n",
        "from imitation.algorithms.bc import BC\n",
        "import imitation.augment as il_augment\n",
        "from imitation.data import rollout\n",
        "import imitation.data.types as il_types\n",
        "from imitation.util.util import make_vec_env\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import skvideo.io as vidio\n",
        "import stable_baselines3.common.policies as sb3_pols\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as th_data\n",
        "\n",
        "import magical\n",
        "from magical.evaluation import EvaluationProtocol\n",
        "\n",
        "magical.register_envs()\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "# download trajectories\n",
        "magical.try_download_demos(dest=\"demos\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcEkoJI9_gh-"
      },
      "source": [
        "class MAGICALNet(nn.Module):\n",
        "    \"\"\"Custom CNN for MAGICAL policies.\"\"\"\n",
        "    def __init__(self, observation_space, out_chans=256, width=2):\n",
        "        super().__init__()\n",
        "        w = width\n",
        "        def conv_block(i, o, k, s, p, b=False):\n",
        "            return [\n",
        "                # batch norm has its own bias, so don't add one to conv layers by default\n",
        "                nn.Conv2d(i, o, kernel_size=k, stride=s, padding=p, bias=b,\n",
        "                          padding_mode='zeros'),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(o)\n",
        "            ]\n",
        "        conv_layers = [\n",
        "            *conv_block(i=observation_space.shape[0], o=32*w, k=5, s=1, p=2, b=True),\n",
        "            *conv_block(i=32*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "        ]\n",
        "        # final FC layer to make feature maps the right size\n",
        "        test_tensor = torch.zeros((1,) + observation_space.shape)\n",
        "        for layer in conv_layers:\n",
        "            test_tensor = layer(test_tensor)\n",
        "        fc_in_size = np.prod(test_tensor.shape)\n",
        "        reduction_layers = [\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(fc_in_size, out_chans),\n",
        "            # Stable Baselines will add extra affine layer on top of this reLU\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        self.features_dim = out_chans\n",
        "        all_layers = [*conv_layers, *reduction_layers]\n",
        "        self.feature_generator = nn.Sequential(*all_layers)\n",
        "\n",
        "    def forward(self, x, traj_info=None):\n",
        "        return self.feature_generator(x)\n",
        "\n",
        "class ImitationEvaluationProtocol(EvaluationProtocol):\n",
        "    \"\"\"EvaluationProtocol is an abstract base class which is able to evaluate a MAGICAL policy on a set of test\n",
        "    environments & appropriate calculate confidence intervals & other statistics for the mean score in each environment.\n",
        "    Concrete instances of EvaluationProtocol must provide their own method for generating trajectories, and also provide\n",
        "    a name for the resulting evaluation data (which will be written into the Pandas dataframe used to compute\n",
        "    statistics).\n",
        "\n",
        "    This subclass of EvaluationProtocol uses the `imitation` library to generate the require trajectories.\"\"\"\n",
        "    def __init__(self, policy, run_description, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.policy = policy\n",
        "        self.run_description = run_description\n",
        "\n",
        "    @property\n",
        "    def run_id(self):\n",
        "        # simple string describing this run\n",
        "        return self.run_description\n",
        "\n",
        "    def obtain_scores(self, env_name):\n",
        "        vec_env = make_vec_env(env_name=env_name, n_envs=25)  # sample in parallel\n",
        "        trajectories = rollout.generate_trajectories(self.policy,\n",
        "                                                     vec_env,\n",
        "                                                     sample_until=rollout.min_episodes(self.n_rollouts),\n",
        "                                                     deterministic_policy=False)\n",
        "        # the MAGICAL score is passed through the final info dict in each trajectory\n",
        "        scores = [traj.infos[-1]['eval_score'] for traj in trajectories]\n",
        "        return scores\n",
        "\n",
        "def create_policy_video(policy, demo_env_name, traj_per_env=1, fps=24):\n",
        "    \"\"\"Create a video showing policy performance on the demo environment and all test environments.\"\"\"\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".mp4\") as fp:\n",
        "        writer = vidio.FFmpegWriter(fp.name, outputdict={'-r': str(fps), '-vcodec': 'libx264', '-pix_fmt': 'yuv420p'})\n",
        "\n",
        "        # for both demo environment + test environments, we append `traj_per_env` demos to the video\n",
        "        env_name_list = (demo_env_name, ) + magical.DEMO_ENVS_TO_TEST_ENVS_MAP[demo_env_name]\n",
        "        for env_name in env_name_list:\n",
        "            vec_env = make_vec_env(env_name=env_name, n_envs=min(traj_per_env, 25))\n",
        "            trajectories = rollout.generate_trajectories(policy, vec_env,\n",
        "                                                        sample_until=rollout.min_episodes(traj_per_env),)\n",
        "            vec_env.close()\n",
        "            for traj in trajectories:\n",
        "                for obs in traj.obs:\n",
        "                    # each observation is a frame stack; we write only the last (RGB) frame, transposed to be channels-last\n",
        "                    rgb_frame = np.transpose(obs, (1, 2, 0))\n",
        "                    vid_h, vid_w = rgb_frame.shape[:2]\n",
        "                    writer.writeFrame(rgb_frame)\n",
        "\n",
        "        # finish writing video\n",
        "        writer.close()\n",
        "\n",
        "        # now convert video to base64 so we can generate a <video> tag that works with the notebook\n",
        "        vid_base64 = base64.b64encode(fp.read()).decode('utf-8')\n",
        "        print('Video size (MB):', len(vid_base64) / 1e6)\n",
        "        html_string = f\"\"\"<video width=\"{vid_w}\" height=\"{vid_h}\" muted controls loop autoplay>\n",
        "            <source src=\"data:video/mp4;base64,{vid_base64}\" type=\"video/mp4\">\n",
        "            No &lt;video&gt; tag support :(\n",
        "        </video>\"\"\"\n",
        "        return display.HTML(data=html_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD3zdcLLlt1a"
      },
      "source": [
        "## Running MAGICAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hfHaZG67iDH"
      },
      "source": [
        "env_ident = 'MoveToCorner'\n",
        "preproc_name = 'LoResCHW4E'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-knOWB17iDH"
      },
      "source": [
        "demo_paths_by_env = {\n",
        "    'MoveToCorner': glob.glob('demos/move-to-corner/demo-*.pkl.gz'),\n",
        "}\n",
        "demo_paths = demo_paths_by_env[env_ident]\n",
        "# Gym env name with preprocessor\n",
        "env_name = f'{env_ident}-Demo-{preproc_name}-v0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHSVWkb87iDI"
      },
      "source": [
        "env = gym.make(env_name)\n",
        "demo_dicts = magical.load_demos(demo_paths[:10])\n",
        "demo_trajs = []\n",
        "orig_env_name = None  # we will read this from the demos dicts\n",
        "for demo_dict in demo_dicts:\n",
        "    # each demo dict has keys ['trajectory', 'score', 'env_name']\n",
        "    # (trajectory contains the actual data, and score is generally 1.0 for demonstrations)\n",
        "    orig_env_name = demo_dict['env_name']\n",
        "    demo_trajs.append(demo_dict['trajectory'])\n",
        "demo_trajs_preproc = magical.preprocess_demos_with_wrapper(demo_trajs, orig_env_name, preproc_name=preproc_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiEV5Nr3jx7x"
      },
      "source": [
        "# Build dataset in the format required by imitation. Note that traj.obs contains the final observation after the last\n",
        "# action, so we drop the last observation when concatenating trajectories.\n",
        "all_obs = np.concatenate([traj.obs[:-1] for traj in demo_trajs_preproc], axis=0)\n",
        "all_acts = np.concatenate([traj.acts for traj in demo_trajs_preproc], axis=0)\n",
        "dataset = il_types.TransitionsMinimal(obs=all_obs, acts=all_acts, infos=[{}] * len(all_obs))\n",
        "data_loader = th_data.DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=il_types.transitions_collate_fn)\n",
        "augmenter = il_augment.StandardAugmentations.from_string_spec(\n",
        "       'rotate,translate,noise', stack_color_space=il_augment.ColorSpace.RGB)\n",
        "bc_trainer = BC(\n",
        "    observation_space=env.observation_space,\n",
        "    action_space=env.action_space,\n",
        "    policy_class=sb3_pols.ActorCriticCnnPolicy,\n",
        "    policy_kwargs=dict(features_extractor_class=MAGICALNet),\n",
        "    expert_data=data_loader,\n",
        "    augmentation_fn=augmenter,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2i3K1Fv_DSN"
      },
      "source": [
        "# try training for longer (e.g. 15,000 batches) to get better performance\n",
        "bc_trainer.train(n_batches=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umG_LZNGCO9y"
      },
      "source": [
        "eval_protocol = ImitationEvaluationProtocol(\n",
        "    policy=bc_trainer.policy,\n",
        "    run_description=f\"notebook-demo-{env_name}\",\n",
        "    demo_env_name=env_name,\n",
        "    # number of rollouts per environment\n",
        "    n_rollouts=15)  # XXX\n",
        "eval_result = eval_protocol.do_eval(verbose=True)\n",
        "eval_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP45aH-pseKI"
      },
      "source": [
        "video = create_policy_video(bc_trainer.policy, env_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GNw1lWu5s6a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPTzyDPk6LV8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}